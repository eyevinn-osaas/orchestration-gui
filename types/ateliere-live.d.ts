/* eslint-disable */
/* tslint:disable */
/*
 * ---------------------------------------------------------------
 * ## THIS FILE WAS GENERATED VIA SWAGGER-TYPESCRIPT-API        ##
 * ##                                                           ##
 * ## AUTHOR: acacode                                           ##
 * ## SOURCE: https://github.com/acacode/swagger-typescript-api ##
 * ---------------------------------------------------------------
 */

export interface ResourcesCompactIngestResponse {
  /**
   * The (optional) name of this Ingest. Empty string if no name has been set
   * @example "Camera1_Ingest"
   */
  name: string;
  /** The list of IDs of the currently available sources in the Ingest */
  sources: ResourcesSourceIDResponse[];
  /** A list of connection_ids of the stream connections originating from this Ingest */
  streams: ResourcesUUIDResponse[];
  /**
   * The component type of this component, always "ingest"
   * @example "ingest"
   */
  type: string;
  /**
   * UUID of this Ingest
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  uuid: string;
  /**
   * The software version of the core library used by this Ingest
   * @example "1.0.0"
   */
  version: string;
}

export interface ResourcesCompactPipelineControlReceiverResponse {
  /** List of all Control Connection going in to this Control Receiver */
  incoming_connections: ResourcesConnectionUUIDResponse[];
  /** List of all Control Connection going out of this Control Receiver */
  outgoing_connections: ResourcesConnectionUUIDResponse[];
}

export interface ResourcesCompactPipelineResponse {
  /** A list of all available Outputs from this Pipeline */
  control_receiver: ResourcesCompactPipelineControlReceiverResponse;
  /** A list of the additional feedback streams provided by the Rendering engine */
  feedback_streams: ResourcesFeedbackStream[];
  /** A list of multi-views currently generated by this Pipeline */
  multiviews: ResourcesIDResponse[];
  /**
   * The (optional) name of this Pipeline. Empty string if no name has been set
   * @example "High Quality"
   */
  name: string;
  /** A list of all available Outputs from this Pipeline */
  outputs: ResourcesNameAndUUIDResponse[];
  /**
   * Public IP or hostname of the Pipeline, controlled by the ACL_MY_PUBLIC_IP environment variable
   * @example "1.2.3.4"
   */
  public_ip: string;
  /** A list of IDs of the streams connected to this Pipeline */
  streams: ResourcesUUIDResponse[];
  /**
   * The component type of this component, always "pipeline"
   * @example "pipeline"
   */
  type: string;
  /**
   * The UUID of this Pipeline
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  uuid: string;
  /**
   * The software version of the core library used by this Pipeline
   * @example "1.0.0"
   */
  version: string;
}

export interface ResourcesConnection {
  /**
   * Current bandwidth usage in bits per second
   * @example 12000000
   */
  bandwidth_bps: number;
  /** The number of packets that has been recorded as dropped (unrecovered, permanently missing) by the receiving side of this interface. */
  dropped_packets: number;
  /**
   * The latency actually used by this connection. This is the maximum of the latency configured for this source and the latency configured by the sender
   * @example 120
   */
  latency_ms: number;
  /**
   * The number of unique original packets that has been recorded as lost by the receiving side of this interface.
   * These lost packets may be recovered by retransmissions and then not be counted as "dropped" packets.
   */
  lost_packets: number;
  /** The number of bytes that has been received on this interface. This metric will only work for protocol SRT. */
  received_bytes: number;
  /** The number of packets that has been received on this interface */
  received_packets: number;
  /** Round trip time in milliseconds */
  round_trip_time_ms: ResourcesRoundTripTimeMs;
}

export interface ResourcesConnectionUUIDResponse {
  /**
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  connection_uuid: string;
}

export interface ResourcesControlPanelResponse {
  /** The number of requests that failed to be sent */
  failed_sent_requests: number;
  /**
   * The (optional) name of this Control Panel. Empty string if no name has been set
   * @example "Control room 1"
   */
  name: string;
  /** List of Control Receivers this Control Panel is connected to */
  outgoing_connections: ResourcesSenderNetworkEndpoint[];
  /** The number of received status messages, counted per sender UUID */
  received_status_messages: ResourcesControlStatusMessageCounter[];
  /** The number of responses to requests, counted per respondent UUID */
  request_responses: ResourcesControlResponseCounter[];
  /** The number of successfully sent requests from this Control Panel */
  sent_requests: number;
  /**
   * The component type of this component, always "control_panel"
   * @example "control_panel"
   */
  type: string;
  /**
   * UUID of this Control Panel
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  uuid: string;
  /**
   * The software version of the core library used by this Control Panel
   * @example "1.0.0"
   */
  version: string;
}

export interface ResourcesControlReceiverStatusResponse {
  /** The number of requests from other components that have been delivered to the Rendering Engine */
  delivered_requests: number;
  /** The number of requests that failed to be sent */
  failed_sent_requests: number;
  /** The number of responses to requests that failed to send */
  failed_sent_responses: number;
  /** The number of status messages that failed to be sent */
  failed_sent_status_messages: number;
  /** List of incoming connections from Control Panels and other Control Receivers */
  incoming_connections: ResourcesReceiverNetworkEndpoint[];
  /** The listening interface of this Control Receiver for incoming messages. Null if no interface is configured yet */
  listening_interface: ResourcesListeningInterface;
  /** List of other Control Receivers this Control Receiver is connected to for outgoing messages */
  outgoing_connections: ResourcesSenderNetworkEndpoint[];
  /** The number of received requests, counted per sender UUID */
  received_requests: ResourcesControlRequestCounter[];
  /** The number of responses to requests sent from this Control Receiver, counted per respondent UUID */
  request_responses: ResourcesControlResponseCounter[];
  /** The number of requests in queue, waiting to be delivered to the Rendering Engine */
  requests_in_queue: number;
  /** The number of successfully sent requests from this Control Receiver */
  sent_requests: number;
  /** The number of responses to requests that was successfully sent */
  sent_responses: number;
  /** The number of successfully sent status messages from this Control Receiver */
  sent_status_messages: number;
}

export interface ResourcesControlRequestCounter {
  /** Number of requests received from the sender */
  count: number;
  /**
   * UUID of the sender
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  sender_uuid: string;
}

export interface ResourcesControlResponseCounter {
  /** Number of request responses received from this respondent */
  count: number;
  /**
   * UUID of the respondent
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  respondent_uuid: string;
}

export interface ResourcesControlStatusMessageCounter {
  /** Number of received status messages from this sender */
  count: number;
  /**
   * UUID of the status message sender
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  sender_uuid: string;
}

export interface ResourcesCreateControlConnectionPayload {
  /**
   * The number of milliseconds the messages should be delayed compared to the timestamp of the sending side of the connection, before being delivered to
   * the Rendering Engine on the receiving side. Set to 0 for instant delivery.
   * @format uint32
   * @default 0
   * @example 100
   */
  receiver_side_message_delay_ms?: number;
  /**
   * The network port used by the Pipeline on the receiving side of the connection
   * @format int16
   * @min 1024
   * @max 65535
   * @example 4444
   */
  receiver_side_port: number;
  /**
   * The UUID of the Pipeline on the receiving side of the connection
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  receiver_side_uuid: string;
  /**
   * The UUID of the Control Panel or Pipeline on the sending side of the connection
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  sender_side_uuid: string;
}

export interface ResourcesCreateControlConnectionResponse {
  /** @example "00000000-0000-0000-0000-000000000000" */
  connection_uuid: string;
}

export interface ResourcesCreateSourcePayload {
  /** The payload for an SRT source to create */
  srt_source?: ResourcesCreateSrtSourcePayload;
}

export interface ResourcesCreateSourceResponse {
  /**
   * The latency for the SRT connection.
   * @example 120
   */
  latency_ms: number;
  /**
   * The locally bound IP address of the SRT source.
   * @example "0.0.0.0"
   */
  local_ip: string;
  /**
   * The locally bound port of the SRT source.
   * @example 1234
   */
  local_port: number;
  /**
   * The mode of the SRT connection. Caller means that the Ingest will initiate the connection to the SRT source.
   * Listener means that the Ingest will listen for an incoming connection from the SRT source.
   * @example "caller"
   */
  mode: string;
  /**
   * The name of the source.
   * @example "SRT from remote reporter"
   */
  name: string;
  /**
   * Only used if mode is set to caller. The IP address of the remote SRT source this source is connected to.
   * @example "1.2.3.4"
   */
  remote_ip: string;
  /**
   * Only used if mode is set to caller. The port used by the remote SRT source this source is connected to.
   * @example 1234
   */
  remote_port: number;
  /**
   * The ID of the source. Unique within the Ingest.
   * @example 42
   */
  source_id: number;
}

export interface ResourcesCreateSrtSourcePayload {
  /**
   * The latency to use for the SRT connection (i.e. the retransmission buffer size), in milliseconds. If set to 0, the Ingest will use the default latency.
   * @default 120
   * @example 120
   */
  latency_ms?: number;
  /**
   * The IP address to bind for the local interface. Used both in caller and listener mode.
   * @default "0.0.0.0"
   * @example "0.0.0.0"
   */
  local_ip?: string;
  /**
   * The port to bind for the local interface. In listener mode this is the port listening for incoming SRT connections, for caller mode this is the local port used in the connection.
   * If set to 0, the Ingest will select a random port.
   * @default 0
   * @example 1234
   */
  local_port?: number;
  /**
   * The mode of the SRT connection. Caller means that the Ingest will initiate the connection to the SRT source.
   * Listener means that the Ingest will listen for an incoming connection from the SRT source.
   * @example "caller"
   */
  mode: 'caller' | 'listener';
  /**
   * The name of the source.
   * @example "SRT from remote reporter"
   */
  name: string;
  /**
   * The passphrase to use for the SRT connection to encrypt the stream. If set to an empty string, no encryption will be used.
   * The passphrase must be empty or 10-79 characters long.
   * @example "my_sÃ¼per_$ecret_pa$$word"
   */
  passphrase?: string;
  /**
   * Only used if mode is set to caller. The IP address of the SRT source to connect to.
   * @example "1.2.3.4"
   */
  remote_ip?: string;
  /**
   * Only used if mode is set to caller. The port of the SRT source to connect to.
   * @example 1234
   */
  remote_port?: number;
}

export interface ResourcesCreateStreamPayload {
  /**
   * The number of milliseconds after a frame was timestamped by the Ingest,
   * it should be delivered to the Rendering engine. Note: this parameter should include the max_network_latency_ms,
   * i.e. alignment_ms > max_network_latency_ms + some jitter margin
   * @example 200
   */
  alignment_ms: number;
  /**
   * The compression format used for the audio stream.
   * @example "AAC-LC"
   */
  audio_format: 'AAC-LC' | 'Opus';
  /**
   * The audio mapping to use for mapping the input audio channels in the Ingest to output channels in the Pipeline. Formatted as a JSON array. The input
   * channels are listed in the same order as they will be outputted in the Pipeline, but with additional brackets to group two channels as a stereo pair.
   * Stereo pair must have channels located next to each other in the output, but that is not required in the input.
   * For example the mapping [2, [0, 1], [6, 10]] means that the output order of the channels are 2, 0, 1, 6, 10 in the Pipeline, with the first one,
   * (input channel 2) encoded as a mono channel, and input channels 0,1 and 6,10 encoded as stereo pairs (left, right). Input channels 3-5 and 7-9 are not
   * transported in this case. These five channels are mapped to channels 0-4 in the Pipeline.
   * Note that the mapping [2, 0, 1, 6, 10] will yield the same result in the Pipeline as the example above, but would be less effective, as all channels would
   * be encoded as mono channels.
   * @default "[[0,1]]"
   * @example "[[0, 1]]"
   */
  audio_mapping?: string;
  /**
   * Sampling frequency used in the audio stream in Hz
   * @min 1
   * @default 48000
   * @example 48000
   */
  audio_sampling_frequency?: number;
  /**
   * The bit depth of the encoded stream, 8 or 10 bits per component
   * @example 10
   */
  bit_depth: 8 | 10;
  /**
   * If set to true the video in this stream is converted from narrow color range to full color range,
   * otherwise the color range is kept. This should be set to true for streams of narrow range sources (such as SDI sources).
   * @default false
   * @example false
   */
  convert_color_range?: boolean;
  /**
   * The encoder implementation to use for encoding this stream.
   * "Auto" will make the Ingest select a suitable encoder that is supported by the hardware
   * @default "nvidia_gpu"
   * @example "nvidia_gpu"
   */
  encoder?: 'auto' | 'intel_gpu' | 'nvidia_gpu';
  /**
   * The id of the device supported by the selected encoder to use for encoding the stream.
   * For GPU-based encoders this number will generally mean the id of the GPU.
   * "auto" will select the most suitable device
   * @default "auto"
   * @example "auto"
   */
  encoder_device?: 'auto' | '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7';
  /**
   * The compression format used for the video stream.
   * @example "HEVC"
   */
  format: 'AVC' | 'HEVC';
  /**
   * The frame rate denominator of the video.
   * @min 1
   * @default 1
   * @example 1
   */
  frame_rate_d?: number;
  /**
   * The frame rate numerator of the video.
   * @min 1
   * @default 50
   * @example 50
   */
  frame_rate_n?: number;
  /**
   * The group of pictures length to used when encoding, i.e. the length in frames between two IDR frames.
   * @default 50
   * @example 50
   */
  gop_length?: number;
  /**
   * The height of the video frames in the stream in pixels. In case the source stream has another height, the Ingest will rescale the video.
   * @min 100
   * @max 8192
   * @example 1080
   */
  height: number;
  /**
   * UUID of Ingest to get the stream from
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  ingest_id: string;
  /**
   * The input slot of the Rendering engine this source will be "plugged in" to. Think of this as a virtual variant
   * of an SDI input port on a hardware mixer. This input slot will be used to identify the source from the control
   * panel later, so pressing "cut to camera 5" will cut to the camera on input slot 5. Only one source can be
   * connected to one slot at a time, so if the slot is already used, the request will be denied.
   * @min 0
   * @example 1
   */
  input_slot: number;
  /** The network interfaces to use for this stream */
  interfaces: ResourcesStreamInterfacePayload[];
  /**
   * The number of milliseconds the network transport protocol is allowed to resend
   * packets before they are considered lost
   * @min 0
   * @example 50
   */
  max_network_latency_ms: number;
  /**
   * The picture mode, selecting if P and B-frames should be used and the number of consecutive B-frames.
   * @default "pic_mode_ip"
   * @example "pic_mode_ip"
   */
  pic_mode?: 'pic_mode_i' | 'pic_mode_ip' | 'pic_mode_ipb' | 'pic_mode_ipbb';
  /**
   * UUID of the Pipeline to connect the stream to
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  pipeline_id: string;
  /**
   * ID of the source within the Ingest that will be used
   * @min 0
   * @example 1
   */
  source_id: number;
  /**
   * The encoder speed/quality balance setting.
   * @example "better"
   */
  speed_quality_balance:
    | 'fastest'
    | 'faster'
    | 'fast'
    | 'balanced'
    | 'good'
    | 'better'
    | 'best';
  /**
   * The target kilobit rate used when encoding the stream.
   * @min 1
   * @example 25000
   */
  video_kilobit_rate: number;
  /**
   * The width of the video frames in the stream in pixels. In case the source stream has another width, the Ingest will rescale the video.
   * @min 100
   * @max 8192
   * @example 1920
   */
  width: number;
}

export interface ResourcesCreateStreamResponse {
  /**
   * The UUID of the stream connection that was created
   * @example "00000000-0000-0000-0000-000000000000"
   */
  stream_uuid: string;
}

export interface ResourcesFeedbackStream {
  /**
   * The input slot this feedback stream is connected to
   * @example 1
   */
  input_slot: number;
  /**
   * A human readable name on this stream, provided by the rendering engine
   * @example "Program out"
   */
  name: string;
}

export interface ResourcesHTTPError {
  /**
   * HTTP error code
   * @example 400
   */
  code: number;
  /**
   * A human readable error message
   * @example "status bad request"
   */
  message: string;
}

export interface ResourcesIDResponse {
  /**
   * Id of the resource
   * @example 12
   */
  id: number;
}

export interface ResourcesIngestResponse {
  /**
   * Version of the Black Magic Design DeckLink API
   * @example "1.0.0"
   */
  bmd_version: string;
  /** The encoders available in this Ingest */
  encoders: TypesEncoderData[];
  /**
   * The (optional) name of this Ingest. Empty string if no name has been set
   * @example "Camera1_Ingest"
   */
  name: string;
  /**
   * Version of the NewTek NDI API
   * @example "1.0.0"
   */
  ndi_version: string;
  /** The list of currently available sources in the Ingest */
  sources: ResourcesSourceResponse[];
  /** A list of the stream connections originating from this Ingest */
  streams: ResourcesIngestStreamResponse[];
  /**
   * The component type of this component, always "ingest"
   * @example "ingest"
   */
  type: string;
  /**
   * UUID of this Ingest
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  uuid: string;
  /**
   * The software version of the core library used by this Ingest
   * @example "1.0.0"
   */
  version: string;
}

export interface ResourcesIngestStreamResponse {
  /**
   * The average, minimum and maximum time to encode an audio frame in microseconds.
   * Based on the latest 250 frames.
   */
  audio_encode_duration: ResourcesMinMaxAverageTimings;
  /**
   * The compression format of the audio stream
   * @example "AAC-LC"
   */
  audio_format: 'AAC-LC' | 'Opus';
  /**
   * The audio mapping to use for mapping the input audio channels in the Ingest to output channels in the Pipeline. Formatted as a JSON array. See resources.CreateStreamPayload for more information
   * @example "[[0, 1]]"
   */
  audio_mapping: string;
  /**
   * The bit depth of the compressed video stream, 8 or 10 bits
   * @example 10
   */
  bit_depth: 8 | 10;
  /** The number of video frames dropped due to the encoder queue being full */
  dropped_video_frames: number;
  /**
   * The number of successfully encoded audio frames. Note that this will usually differ from the encoded_video_frames counter, as
   * the audio is encoded in frames of 1024 samples, which does not match the number of audio samples per video frame (960 for 50 FPS)
   */
  encoded_audio_frames: number;
  /** The number of successfully encoded video frames */
  encoded_video_frames: number;
  /** The encoder implementation used for encoding this stream */
  encoder: string;
  /**
   * The id of the device supported by the selected encoder that is used for encoding the stream.
   * For GPU-based encoders this number will generally mean the id of the GPU.
   */
  encoder_device: string;
  /** The number of audio frames that failed encoding (either due to not being accepted by the encoder, or an internal error during the encoding) */
  failed_encoded_audio_frames: number;
  /** The number of video frames that failed encoding (either due to not being accepted by the encoder, or an internal error during the encoding) */
  failed_encoded_video_frames: number;
  /** The number of audio frames that failed to be sent to the network layer */
  failed_sent_audio_frames: number;
  /** The number of video frames that failed to be sent to the network layer */
  failed_sent_video_frames: number;
  /**
   * The compression format of the video stream
   * @example "HEVC"
   */
  format: 'AVC' | 'HEVC';
  /**
   * The frame rate denominator
   * @example 1
   */
  frame_rate_d: number;
  /**
   * The frame rate numerator
   * @example 50
   */
  frame_rate_n: number;
  /**
   * The Group of pictures length, i.e. the distance in frames between two IDR-frames
   * @example 8
   */
  gop_length: number;
  /** The number of audio frames that have been grabbed from the input interface */
  grabbed_audio_frames: number;
  /** The number of video frames that have been grabbed from the input interface */
  grabbed_video_frames: number;
  /**
   * The height of the video in the stream in pixels
   * @example 1080
   */
  height: number;
  /** The network interfaces and corresponding protocols used in this stream */
  interfaces: ResourcesStreamInterfaceIngest[];
  /** The maximum number of milliseconds the network protocols used in this stream are allowed to wait for retransmission of lost network packets */
  max_network_latency_ms: number;
  /**
   * The picture mode, selecting order of P and B frames
   * @example "pic_mode_ipb"
   */
  pic_mode: 'pic_mode_i' | 'pic_mode_ip' | 'pic_mode_ipb' | 'pic_mode_ipbb';
  /**
   * UUID of the Pipeline in the other end of this stream.
   * @example "00000000-0000-0000-0000-000000000000"
   */
  pipeline_uuid: string;
  /**
   * The average, minimum and maximum processing time of audio frames in this stream measured from the capture time to handover to the network interface.
   * Based on the latest 250 frames.
   */
  processing_time_audio: ResourcesMinMaxAverageTimings;
  /**
   * The average, minimum and maximum processing time of video frames in this stream measured from the capture time to handover to the network interface.
   * Based on the latest 250 frames.
   */
  processing_time_video: ResourcesMinMaxAverageTimings;
  /**
   * The number of audio frames that have been sent to the network. Note that this will usually differ from the sent_video_frames counter, as
   * the audio is encoded in frames of 1024 samples, which does not match the number of audio samples per video frame (960 for 50 FPS)
   */
  sent_audio_frames: number;
  /** The number of video frames that have been sent to the network */
  sent_video_frames: number;
  /** ID of the source being streamed. Unique within the system. */
  source_id: number;
  /**
   * The tradeoff between fast encoding (and lower quality) or higher quality (and slower/more performance demanding encoding)
   * @example "balanced"
   */
  speed_quality_balance:
    | 'fastest'
    | 'faster'
    | 'fast'
    | 'balanced'
    | 'good'
    | 'better'
    | 'best';
  /**
   * The UUID of this stream connection as set when creating the stream.
   * @example "00000000-0000-0000-0000-000000000000"
   */
  stream_uuid: string;
  /**
   * The average, minimum and maximum time to encode a video frame in microseconds.
   * Based on the latest 250 frames.
   */
  video_encode_duration: ResourcesMinMaxAverageTimings;
  /** The maximum number of video frames that can be kept in queue before it is full */
  video_frame_queue_capacity: number;
  /** The number of video frames currently in queue to the encoder */
  video_frames_in_queue: number;
  /**
   * The kilobit rate of the video
   * @example 32000
   */
  video_kilobit_rate: number;
  /**
   * The width of the video in the stream in pixels
   * @example 1920
   */
  width: number;
}

export interface ResourcesListeningInterface {
  /** The IP address this Control Receiver is listening to */
  ip: string;
  /** Information on a pending connection that the Control Receiver is currently awaiting, if any. Null in case there is no pending connection */
  pending_connection: ResourcesPendingConnection;
  /** The network port this Control Receiver is listening to */
  port: number;
}

export interface ResourcesMinMaxAverageTimings {
  /** Average time in micro seconds */
  avg: number;
  /** Maximum time in micro seconds */
  max: number;
  /** Minimum time in micro seconds */
  min: number;
}

export interface ResourcesMultiviewLayout {
  /**
   * True if audio level indicators should be included in the multiview
   * @default true
   */
  audio_levels: boolean;
  /**
   * Height in pixels of the composited image
   * @min 100
   * @max 8192
   * @example 1080
   */
  output_height: number;
  /**
   * Width in pixels of the composited image
   * @min 100
   * @max 8192
   * @example 1920
   */
  output_width: number;
  views: ResourcesView[];
}

export interface ResourcesMultiviewOutputPayload {
  /**
   * The type of output stream to use, MPEG-TS stream over UDP or SRT
   * @example "MPEG-TS-SRT"
   */
  format: 'MPEG-TS-UDP' | 'MPEG-TS-SRT';
  /**
   * The frame rate denominator of the multi-view output
   * @min 1
   * @default 1
   * @example 1
   */
  frame_rate_d?: number;
  /**
   * The frame rate numerator of the multi-view output
   * @min 1
   * @default 50
   * @example 50
   */
  frame_rate_n?: number;
  /**
   * The local IP address to bind to. Only used for format "MPEG-TS-UDP" or format "MPEG-TS-SRT".
   * @default "0.0.0.0"
   * @example "0.0.0.0"
   */
  local_ip?: string;
  /**
   * The local port to bind to. Only used for format "MPEG-TS-UDP" or format "MPEG-TS-SRT".
   * @default 0
   * @example 1234
   */
  local_port?: number;
  /**
   * The picture mode, selecting the cadence of P and B frames
   * @default "pic_mode_ip"
   * @example "pic_mode_ipb"
   */
  pic_mode?: 'pic_mode_i' | 'pic_mode_ip' | 'pic_mode_ipb' | 'pic_mode_ipbb';
  /**
   * The IPv4 or IPv6 address of the remote to send the stream to. Only used for format "MPEG-TS-UDP" or format "MPEG-TS-SRT" when srt_mode is set to "caller".
   * @example "0.0.0.0"
   */
  remote_ip?: string;
  /**
   * The port on the remote to send the stream to. Only used for format "MPEG-TS-UDP" or format "MPEG-TS-SRT" when srt_mode is set to "caller".
   * @example 1234
   */
  remote_port?: number;
  /**
   * The tradeoff between fast encoding (and lower quality) or higher quality (and slower/more performance demanding encoding)
   * @default "balanced"
   * @example "fast"
   */
  speed_quality_balance?:
    | 'fastest'
    | 'faster'
    | 'fast'
    | 'balanced'
    | 'good'
    | 'better'
    | 'best';
  /**
   * The SRT latency (i.e. the retransmission buffer size) setting to use, in milliseconds. Only used if format is "MPEG-TS-SRT"
   * @default 120
   * @example 120
   */
  srt_latency_ms?: number;
  /**
   * The mode to use for the SRT connection. Only used if format is "MPEG-TS-SRT"
   * @default "listener"
   * @example "listener"
   */
  srt_mode?: 'caller' | 'listener';
  /**
   * The SRT passphrase for encrypting the stream. Must be 10 to 79 characters long. The passphrase must match in the receiving SRT connection. Use empty string to disable encryption.
   * @example ""
   */
  srt_passphrase?: string;
  /**
   * The SRT Stream ID to use. Only used if format is "MPEG-TS-SRT" and srt_mode is set to "caller"
   * @example "#!::u=admin,r=bluesbrothers1_hi"
   */
  srt_stream_id?: string;
  /**
   * The video format to use when encoding the video stream
   * @example "AVC"
   */
  video_format: 'AVC' | 'HEVC';
  /**
   * The kilobit rate to encode the composited video stream to
   * @min 1
   * @example 5000
   */
  video_kilobit_rate: number;
}

export interface ResourcesMultiviewOutputResponse {
  /**
   * Number of multi-view frames that has failed to render since this multi-view output started
   * @example 2
   */
  failed_rendered_frames: number;
  /**
   * The type of output stream that is used
   * @example "MPEG-TS-SRT"
   */
  format: 'MPEG-TS-SRT' | 'MPEG-TS-UDP';
  /**
   * The frame rate denominator of the multi-view output
   * @min 1
   * @example 1
   */
  frame_rate_d: number;
  /**
   * The frame rate numerator of the multi-view output
   * @min 1
   * @example 50
   */
  frame_rate_n: number;
  /** Statistics from SRT. Only included in case format is MPEG-TS-SRT. */
  mpeg_ts_srt?: ResourcesOutputActiveStreamMpegTsSrt;
  /** Statistics from UDP. Only included in case format is MPEG-TS-UDP. */
  mpeg_ts_udp?: ResourcesOutputActiveStreamMpegTsUDP;
  /**
   * Number of multi-view frames that has been successfully rendered since this multi-view output started
   * @example 1234
   */
  rendered_frames: number;
  /** The average, minimum and maximum time to render a frame on this multi-view output in microseconds, based on the latest 250 frames. */
  rendering_duration: ResourcesMinMaxAverageTimings;
}

export interface ResourcesMultiviewPayload {
  /** @default true */
  audio_levels: boolean;
  /** List of the views in the multi-view output */
  views: ResourcesView[];
}

export interface ResourcesNameAndUUIDResponse {
  /**
   * Name of the resource
   * @example "My name"
   */
  name: string;
  /**
   * UUID of the resource
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  uuid: string;
}

export interface ResourcesOutputActiveStream {
  /**
   * The type of output stream that is used
   * @example "MPEG-TS-SRT"
   */
  format: 'MPEG-TS-SRT' | 'MPEG-TS-UDP' | 'MPEG-TS-File';
  /** The ID of the output stream */
  id: number;
  /** Statistics from File writer. Only included in case format is MPEG-TS-File. */
  mpeg_ts_file?: ResourcesOutputActiveStreamMpegTsFile;
  /** Statistics from SRT. Only included in case format is MPEG-TS-SRT. */
  mpeg_ts_srt?: ResourcesOutputActiveStreamMpegTsSrt;
  /** Statistics from UDP. Only included in case format is MPEG-TS-UDP. */
  mpeg_ts_udp?: ResourcesOutputActiveStreamMpegTsUDP;
}

export interface ResourcesOutputActiveStreamMpegTsFile {
  /**
   * The compression format used for the audio stream.
   * @example "ADTS"
   */
  audio_format: 'ADTS';
  /**
   * The target kilobit rate used when encoding the audio stream
   * @example 128
   */
  audio_kilobit_rate: number;
  /**
   * The number of bytes written to file
   * @example 456123456
   */
  bytes_written: number;
  /**
   * The number of audio frames that have been successfully encoded since the stream started. Note that this metric will usually be
   * lower than the number of video frames, as the audio is packed 1024 samples per packet using ADTS and a video frame in 50 FPS corresponds
   * to 960 audio frames at 48000 Hz sampling rate.
   */
  encoded_audio_frames: number;
  /** The number of video frames that have been successfully encoded since the stream started */
  encoded_video_frames: number;
  /** The number of audio frames that have failed to be encoded since the stream started */
  failed_encoded_audio_frames: number;
  /** The number of video frames that have failed to be encoded since the stream started */
  failed_encoded_video_frames: number;
  /**
   * The name of the file this stream is written to
   * @example "my_file.ts"
   */
  filename: string;
  /**
   * The number of muxed audio frames
   * @example 4582
   */
  muxed_audio_frames: number;
  /**
   * The number of muxed video frames
   * @example 4581
   */
  muxed_video_frames: number;
  /**
   * The picture mode, the cadence of P and B frames
   * @example "pic_mode_ipb"
   */
  pic_mode: 'pic_mode_i' | 'pic_mode_ip' | 'pic_mode_ipb' | 'pic_mode_ipbb';
  /**
   * The tradeoff between fast encoding (and lower quality) or higher quality (and slower/more performance demanding encoding)
   * @example "fast"
   */
  speed_quality_balance:
    | 'fastest'
    | 'faster'
    | 'fast'
    | 'balanced'
    | 'good'
    | 'better'
    | 'best';
  /**
   * The bit depth of the produced stream, 8 or 10 bits per component
   * @example 10
   */
  video_bit_depth: 8 | 10;
  /**
   * The compression format used for the video stream.
   * @example "HEVC"
   */
  video_format: 'AVC' | 'HEVC';
  /**
   * The group of pictures length to used when encoding, i.e. the length in frames between two IDR frames
   * @example 50
   */
  video_gop_length: number;
  /**
   * The target kilobit rate used when encoding the video stream
   * @example 2000
   */
  video_kilobit_rate: number;
}

export interface ResourcesOutputActiveStreamMpegTsSrt {
  /**
   * The compression format used for the audio stream.
   * @example "ADTS"
   */
  audio_format: 'ADTS';
  /**
   * The target kilobit rate used when encoding the audio stream
   * @example 128
   */
  audio_kilobit_rate: number;
  /** Array with client specific statistics for all connected clients. */
  clients: ResourcesOutputSrtClient[];
  /**
   * The number of audio frames that have been successfully encoded since the stream started. Note that this metric will usually be
   * lower than the number of video frames, as the audio is packed 1024 samples per packet using ADTS and a video frame in 50 FPS corresponds
   * to 960 audio frames at 48000 Hz sampling rate.
   */
  encoded_audio_frames: number;
  /** The number of video frames that have been successfully encoded since the stream started */
  encoded_video_frames: number;
  /** The number of audio frames that have failed to be encoded since the stream started */
  failed_encoded_audio_frames: number;
  /** The number of video frames that have failed to be encoded since the stream started */
  failed_encoded_video_frames: number;
  /**
   * The latency configured for this end of the SRT connection. The actual SRT latency can be found for each client in the clients array
   * @example 120
   */
  latency_ms: number;
  /**
   * The local bind IP of this SRT connection
   * @example "0.0.0.0"
   */
  local_ip: string;
  /**
   * The local bind port of this SRT connection
   * @example 1234
   */
  local_port: number;
  /**
   * The number of muxed audio frames
   * @example 4582
   */
  muxed_audio_frames: number;
  /**
   * The number of muxed video frames
   * @example 4581
   */
  muxed_video_frames: number;
  /**
   * The picture mode, the cadence of P and B frames
   * @example "pic_mode_ipb"
   */
  pic_mode: 'pic_mode_i' | 'pic_mode_ip' | 'pic_mode_ipb' | 'pic_mode_ipbb';
  /**
   * The remote IPv4 or IPv6 address this SRT connection sends to. Only if srt_mode is "caller".
   * @example "0.0.0.0"
   */
  remote_ip: string;
  /**
   * The remote port this SRT connection sends to. Only if srt_mode is "caller"
   * @example 1234
   */
  remote_port: number;
  /**
   * The tradeoff between fast encoding (and lower quality) or higher quality (and slower/more performance demanding encoding)
   * @example "fast"
   */
  speed_quality_balance:
    | 'fastest'
    | 'faster'
    | 'fast'
    | 'balanced'
    | 'good'
    | 'better'
    | 'best';
  /**
   * The mode this SRT connection is using, either "caller" or "listener"
   * @example "listener"
   */
  srt_mode: string;
  /**
   * The bit depth of the produced stream, 8 or 10 bits per component
   * @example 10
   */
  video_bit_depth: 8 | 10;
  /**
   * The compression format used for the video stream.
   * @example "HEVC"
   */
  video_format: 'AVC' | 'HEVC';
  /**
   * The group of pictures length to used when encoding, i.e. the length in frames between two IDR frames
   * @example 50
   */
  video_gop_length: number;
  /**
   * The target kilobit rate used when encoding the video stream
   * @example 2000
   */
  video_kilobit_rate: number;
}

export interface ResourcesOutputActiveStreamMpegTsUDP {
  /**
   * The compression format used for the audio stream.
   * @example "ADTS"
   */
  audio_format: 'ADTS';
  /**
   * The target kilobit rate used when encoding the audio stream
   * @example 128
   */
  audio_kilobit_rate: number;
  /**
   * The number of audio frames that have been successfully encoded since the stream started. Note that this metric will usually be
   * lower than the number of video frames, as the audio is packed 1024 samples per packet using ADTS and a video frame in 50 FPS corresponds
   * to 960 audio frames at 48000 Hz sampling rate.
   */
  encoded_audio_frames: number;
  /** The number of video frames that have been successfully encoded since the stream started */
  encoded_video_frames: number;
  /** The number of audio frames that have failed to be encoded since the stream started */
  failed_encoded_audio_frames: number;
  /** The number of video frames that have failed to be encoded since the stream started */
  failed_encoded_video_frames: number;
  /**
   * Number of UDP packets that failed to send on the UDP connection
   * @example 2
   */
  failed_sent_packets: number;
  /**
   * The local bind IP of this UDP connection
   * @example "0.0.0.0"
   */
  local_ip: string;
  /**
   * The local bind port of this UDP connection
   * @example 1234
   */
  local_port: number;
  /**
   * The number of muxed audio frames
   * @example 4582
   */
  muxed_audio_frames: number;
  /**
   * The number of muxed video frames
   * @example 4581
   */
  muxed_video_frames: number;
  /**
   * The picture mode, the cadence of P and B frames
   * @example "pic_mode_ipb"
   */
  pic_mode: 'pic_mode_i' | 'pic_mode_ip' | 'pic_mode_ipb' | 'pic_mode_ipbb';
  /**
   * The remote IPv4 or IPv6 address this UDP connection is being sent to.
   * @example "10.10.1.2"
   */
  remote_ip: string;
  /**
   * The remote port this UDP connection is being sent to.
   * @example 1234
   */
  remote_port: number;
  /**
   * Number of successfully sent bytes on the UDP connection
   * @example 432532
   */
  sent_bytes: number;
  /**
   * Number of successfully sent UDP packets on the UDP connection
   * @example 2043
   */
  sent_packets: number;
  /**
   * The tradeoff between fast encoding (and lower quality) or higher quality (and slower/more performance demanding encoding)
   * @example "fast"
   */
  speed_quality_balance:
    | 'fastest'
    | 'faster'
    | 'fast'
    | 'balanced'
    | 'good'
    | 'better'
    | 'best';
  /**
   * The bit depth of the produced stream, 8 or 10 bits per component
   * @example 10
   */
  video_bit_depth: 8 | 10;
  /**
   * The compression format used for the video stream.
   * @example "HEVC"
   */
  video_format: 'AVC' | 'HEVC';
  /**
   * The group of pictures length to used when encoding, i.e. the length in frames between two IDR frames
   * @example 50
   */
  video_gop_length: number;
  /**
   * The target kilobit rate used when encoding the video stream
   * @example 2000
   */
  video_kilobit_rate: number;
}

export interface ResourcesOutputInputQueue {
  /** The current number of frames in the input queue */
  current_frames: number;
  /** The total number of frames dropped due to the input queue being full */
  dropped_frames: number;
  /** The maximum number of frames in the input queue */
  frame_capacity: number;
}

export interface ResourcesOutputSrtClient {
  /**
   * Current bandwidth usage in bits per second
   * @example 12000000
   */
  bandwidth_bps: number;
  /**
   * The IPv4 or IPv6 address of the client
   * @example "0.0.0.0"
   */
  ip: string;
  /**
   * The actual latency used by this connection. This is the maximum of the latency configured for this sender and the latency configured by the receiver
   * @example 120
   */
  latency_ms: number;
  /**
   * The port this stream is being sent to.
   * @example 54123
   */
  port: number;
  /** The number of packets that have been retransmitted on this interface */
  retransmitted_packets: number;
  /** Round trip time in milliseconds */
  round_trip_time_ms: ResourcesRoundTripTimeMs;
  /** The number of bytes that have been sent on this interface */
  sent_bytes: number;
  /** The number of packets that have been sent on this interface. This also includes retransmitted packets. */
  sent_packets: number;
}

export interface ResourcesOutputStartStreamPayload {
  /**
   * The compression format used for the audio stream.
   * @default "ADTS"
   * @example "ADTS"
   */
  audio_format?: 'ADTS' | 'None';
  /**
   * The target kilobit rate used when encoding the audio stream
   * @min 1
   * @example 128
   */
  audio_kilobit_rate: number;
  /**
   * The name of the file this stream is written to
   * @example "my_file.ts"
   */
  filename?: string;
  /**
   * The type of output stream that is used
   * @example "MPEG-TS-SRT"
   */
  format: 'MPEG-TS-SRT' | 'MPEG-TS-UDP' | 'MPEG-TS-File';
  /**
   * The local IP address to bind to. Only used for format "MPEG-TS-UDP" or format "MPEG-TS-SRT".
   * @default "0.0.0.0"
   * @example "0.0.0.0"
   */
  local_ip?: string;
  /**
   * The local port to bind to. Only used for format "MPEG-TS-UDP" or format "MPEG-TS-SRT".
   * @default 0
   * @example 1234
   */
  local_port?: number;
  /**
   * The picture mode, selecting the cadence of P and B frames
   * @default "pic_mode_ip"
   * @example "pic_mode_ipb"
   */
  pic_mode?: 'pic_mode_i' | 'pic_mode_ip' | 'pic_mode_ipb' | 'pic_mode_ipbb';
  /**
   * The IPv4 or IPv6 address of the remote to send the stream to. Only used for format "MPEG-TS-UDP" or format "MPEG-TS-SRT" when srt_mode is set to "caller".
   * @example "0.0.0.0"
   */
  remote_ip?: string;
  /**
   * The port on the remote to send the stream to. Only used for format "MPEG-TS-UDP" or format "MPEG-TS-SRT" when srt_mode is set to "caller".
   * @example 1234
   */
  remote_port?: number;
  /**
   * The tradeoff between fast encoding (and lower quality) or higher quality (and slower/more performance demanding encoding)
   * @default "balanced"
   * @example "fast"
   */
  speed_quality_balance?:
    | 'fastest'
    | 'faster'
    | 'fast'
    | 'balanced'
    | 'good'
    | 'better'
    | 'best';
  /**
   * The SRT latency (i.e. the retransmission buffer size) setting to use, in milliseconds. Only used if format is "MPEG-TS-SRT"
   * @default 120
   * @example 120
   */
  srt_latency_ms?: number;
  /**
   * The mode to use for the SRT connection. Only used if format is "MPEG-TS-SRT"
   * @default "listener"
   * @example "listener"
   */
  srt_mode?: 'caller' | 'listener';
  /**
   * The SRT passphrase for encrypting the stream. Must be 10 to 79 characters long. The passphrase must match in the receiving SRT connection. Use empty string to disable encryption.
   * @example ""
   */
  srt_passphrase?: string;
  /**
   * The SRT Stream ID to use. Only used if format is "MPEG-TS-SRT" and srt_mode is set to "caller"
   * @example "#!::u=admin,r=bluesbrothers1_hi"
   */
  srt_stream_id?: string;
  /**
   * The bit depth of the produced stream, 8 or 10 bits per component
   * @example 10
   */
  video_bit_depth: 8 | 10;
  /**
   * The compression format used for the video stream.
   * @example "HEVC"
   */
  video_format: 'AVC' | 'HEVC' | 'None';
  /**
   * The group of pictures length to used when encoding, i.e. the length in frames between two IDR frames
   * @default 50
   * @example 50
   */
  video_gop_length?: number;
  /**
   * The target kilobit rate used when encoding the video stream
   * @min 1
   * @example 2000
   */
  video_kilobit_rate: number;
}

export interface ResourcesOutputStatusResponse {
  /** The list of active output streams */
  active_streams: ResourcesOutputActiveStream[];
  /**
   * The frame rate denominator
   * @example 1
   */
  frame_rate_d: number;
  /**
   * The frame rate numerator
   * @example 50
   */
  frame_rate_n: number;
  /**
   * The height of the video in the output stream in pixels
   * @example 1080
   */
  height: number;
  /** Statistics for the input queue */
  input_queue: ResourcesOutputInputQueue;
  /** The number of lost (never received) frames from the Rendering Engine. The number is calculated based on the gaps in the series of timestamps of the frames received by the Output from the Rendering Engine. */
  lost_frames: number;
  /** Name of this Output */
  name: string;
  /** The number of frames containing audio received from the Rendering Engine */
  received_audio_frames: number;
  /** The number of frames received from the Rendering Engine */
  received_frames: number;
  /** The number of frames containing video received from the Rendering Engine */
  received_video_frames: number;
  /** UUID of this Output */
  uuid: string;
  /**
   * The width of the video in the output stream in pixels
   * @example 1920
   */
  width: number;
}

export interface ResourcesPatchControlConnectionPayload {
  /**
   * The new value for the message delay, i.e. number of milliseconds the messages should be delayed compared to the timestamp of the sending side of the connection,
   * before being delivered to the Rendering Engine on the receiving side. Set to 0 for instant delivery.
   * @format uint32
   * @example 300
   */
  receiver_side_message_delay_ms: number;
}

export interface ResourcesPatchStreamPayload {
  /**
   * New alignment to apply to the stream
   * @example 3200
   */
  alignment_ms: number;
}

export interface ResourcesPendingConnection {
  /**
   * The UUID of this pending Control Connection
   * @example "00000000-0000-0000-0000-000000000000"
   */
  connection_uuid: string;
  /** The message delivery delay that will be used for this pending Control Connection */
  message_delay_ms: number;
  /**
   * The UUID of the Control Panel or Control Receiver that is expected to connect
   * @example "00000000-0000-0000-0000-000000000000"
   */
  sender_uuid: string;
}

export interface ResourcesPipelineMultiviewPayload {
  /** Layout to use for the new multi-view output */
  layout: ResourcesMultiviewLayout;
  /** Output stream settings to use for the new multi-view output */
  output: ResourcesMultiviewOutputPayload;
}

export interface ResourcesPipelineMultiviewResponse {
  /** ID of this multi-view output */
  id: number;
  /** The layout of the views of this multi-view output */
  layout: ResourcesMultiviewLayout;
  /** The output stream settings of this multi-view output */
  output: ResourcesMultiviewOutputResponse;
}

export interface ResourcesPipelineResponse {
  /** A list of all available Control Receivers in this Pipeline */
  control_receiver: ResourcesControlReceiverStatusResponse;
  /** A list of the additional feedback streams provided by the Rendering engine */
  feedback_streams: ResourcesFeedbackStream[];
  /** A list of multi-views currently generated by this Pipeline */
  multiviews: ResourcesPipelineMultiviewResponse[];
  /**
   * The (optional) name of this Pipeline. Empty string if no name has been set
   * @example "High Quality"
   */
  name: string;
  /** A list of all available Outputs from this Pipeline */
  outputs: ResourcesOutputStatusResponse[];
  /**
   * Public IP or hostname of the Pipeline, controlled by the ACL_MY_PUBLIC_IP environment variable
   * @example "1.2.3.4"
   */
  public_ip: string;
  /** A list of the streams connected to this Pipeline */
  streams: ResourcesPipelineStreamResponse[];
  /**
   * The component type of this component, always "pipeline"
   * @example "Pipeline"
   */
  type: string;
  /**
   * The UUID of this Pipeline
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  uuid: string;
  /**
   * The software version of the core library used by this Pipeline
   * @example "1.0.0"
   */
  version: string;
}

export interface ResourcesPipelineStreamResponse {
  /** The currently set alignment, i.e. the number of milliseconds after a frame was timestamped by the Ingest, it is delivered to the Rendering engine */
  alignment_ms: number;
  /**
   * The average, minimum and maximum time to decode an audio frame in microseconds.
   * Based on the latest 250 frames.
   */
  audio_decode_duration: ResourcesMinMaxAverageTimings;
  /**
   * The compression format of the audio stream
   * @example "AAC-LC"
   */
  audio_format: 'AAC-LC' | 'Opus';
  /**
   * The audio mapping to use for mapping the input audio channels in the Ingest to output channels in the Pipeline. Formatted as a JSON array. See resources.CreateStreamPayload for more information
   * @example "[[0, 1]]"
   */
  audio_mapping: string;
  /**
   * The sampling frequency of the audio in Hz
   * @example 48000
   */
  audio_sampling_frequency: number;
  /** True if the video in this stream is converted from narrow range to full color range or false if the color range is kept */
  convert_color_range: boolean;
  /** The number of successfully decoded audio frames */
  decoded_audio_frames: number;
  /** The number of successfully decoded video frames */
  decoded_video_frames: number;
  /** The number of audio/video frames delivered to the rendering engine on time */
  delivered_frames: number;
  /** The number of audio/video frames dropped due to being too late */
  dropped_frames: number;
  /** The number of audio frames that failed to decode */
  failed_decoded_audio_frames: number;
  /** The number of video frames that failed to decode */
  failed_decoded_video_frames: number;
  /**
   * The compression format of the video stream
   * @example "AVC"
   */
  format: 'AVC' | 'HEVC';
  /**
   * The video frame rate denominator
   * @example 1
   */
  frame_rate_d: number;
  /**
   * The video frame rate numerator
   * @example 50
   */
  frame_rate_n: number;
  /**
   * The height in pixels of the video
   * @example 1080
   */
  height: number;
  /**
   * UUID of the Ingest in the other end of this stream.
   * @example "00000000-0000-0000-0000-000000000000"
   */
  ingest_uuid: string;
  /**
   * The input slot this stream is connected to
   * @example 1
   */
  input_slot: number;
  /** List of network interfaces this stream is using to transport the stream */
  interfaces: ResourcesStreamInterfacePipeline[];
  /**
   * The number of frames (audio or video) that have been recorded as lost on the network. This means that all the fragments of the frame have been lost during transport. This counter
   * will be incremented once we receive the first frame after the lost frames, as it is first then we know we have lost frames.
   */
  lost_frames: number;
  /** The maximum number of milliseconds the network protocols used in this stream are allowed to wait for retransmission of lost network packets */
  max_network_latency_ms: number;
  /**
   * The number of audio frames that have been received from the network (Usually lower than the number of video frames,
   * as the audio is packed 1024 samples per packet and a video frame in 50 FPS corresponds to 960 audio frames at 48000 Hz sampling rate)
   */
  received_audio_frames: number;
  /**
   * The number of frames (audio or video) that have been received broken by the receiver. This means some fragments of the frame have been lost on the network, but at least one
   * part of the frame made it to the Pipeline. The frame will be discarded, as it cannot be decoded.
   */
  received_broken_frames: number;
  /** The number of video frames that have been received from the network */
  received_video_frames: number;
  /** The Ingest's ID of the source being streamed. Unique within the Ingest. */
  source_id: number;
  /**
   * The UUID of this stream connection as set when creating the stream. Unique within the system.
   * @example "00000000-0000-0000-0000-000000000000"
   */
  stream_uuid: string;
  /**
   * The average, minimum and maximum "time to arrival" for audio frames in this stream measured from the capture time in the Ingest to handover from the network
   * interface in the Pipeline. Based on the latest 250 frames.
   */
  time_to_arrival_audio: ResourcesMinMaxAverageTimings;
  /**
   * The average, minimum and maximum "time to arrival" for video frames in this stream measured from the capture time in the Ingest to handover from the network
   * interface in the Pipeline. Based on the latest 250 frames.
   */
  time_to_arrival_video: ResourcesMinMaxAverageTimings;
  /**
   * The average, minimum and maximum "time to ready for delivery" of audio frames in this stream measured from the capture time in the Ingest to the time when
   * the frames are put in the delivery queue to the Rendering Engine in the Pipeline. Based on the latest 250 frames.
   */
  time_to_ready_audio: ResourcesMinMaxAverageTimings;
  /**
   * The average, minimum and maximum "time to ready for delivery" of video frames in this stream measured from the capture time in the Ingest to the time when
   * the frames are put in the delivery queue to the Rendering Engine in the Pipeline. Based on the latest 250 frames.
   */
  time_to_ready_video: ResourcesMinMaxAverageTimings;
  /**
   * The average, minimum and maximum time to encode a video frame in microseconds.
   * Based on the latest 250 frames.
   */
  video_decode_duration: ResourcesMinMaxAverageTimings;
  /** The number of video frames currently in queue to the video decoder */
  video_frames_in_queue: number;
  /**
   * The width in pixels of the video
   * @example 1920
   */
  width: number;
}

export interface ResourcesReceiverNetworkEndpoint {
  /**
   * The UUID of this Control Connection
   * @example "00000000-0000-0000-0000-000000000000"
   */
  connection_uuid: string;
  /** The message delivery delay for this Control Connection */
  message_delay_ms: number;
  /** The number of responses and status messages that was received on this connection, but failed to be decoded */
  received_broken: number;
  /** The IPv4 or IPv6 address of the sender in the other end of this connection */
  remote_ip: string;
  /** The network port used by the sender in the other end of this connection */
  remote_port: number;
  /**
   * The UUID of the Control Panel or Control Receiver in the other end of this connection
   * @example "00000000-0000-0000-0000-000000000000"
   */
  sender_uuid: string;
  /**
   * The transport time of messages from this connection in microseconds based on the latest 20 messages. Measured by comparing the send
   * timestamp of the messages with the local time when received.
   */
  transport_duration: ResourcesMinMaxAverageTimings;
}

export interface ResourcesRoundTripTimeMs {
  /**
   * Average round trip time in milliseconds
   * @example 2
   */
  avg: number;
  /**
   * Maximum round trip time in milliseconds
   * @example 3
   */
  max: number;
  /**
   * Minimum round trip time in milliseconds
   * @example 1
   */
  min: number;
}

export interface ResourcesSenderNetworkEndpoint {
  /**
   * The UUID of this connection to a Control Receiver
   * @example "00000000-0000-0000-0000-000000000000"
   */
  connection_uuid: string;
  /**
   * The number of responses and status messages that was received on this connection, but failed to be decoded
   * @example 0
   */
  received_broken: number;
  /**
   * The UUID of the Control Receiver in the other end of this connection
   * @example "00000000-0000-0000-0000-000000000000"
   */
  receiver_uuid: string;
  /**
   * The IPv4 or IPv6 address of the Control Receiver this Control Panel is connected to
   * @example "192.168.0.1"
   */
  remote_ip: string;
  /**
   * The network port on the Control Receiver this Control Panel is connected to
   * @example 1234
   */
  remote_port: number;
}

export interface ResourcesSourceAudioStreamResponse {
  /**
   * The number of channels this audio stream has
   * @example 2
   */
  number_of_channels: number;
  /**
   * The sample rate in Hz of this audio stream
   * @example 48000
   */
  sample_rate: number;
  /**
   * SubID of this audio stream
   * @example 2
   */
  sub_id: number;
}

export interface ResourcesSourceIDResponse {
  /**
   * The SourceID of the source. Unique within the Ingest
   * @example 1
   */
  source_id: number;
}

export interface ResourcesSourceResponse {
  /**
   * Flag to tell if the source is active or not. Active means that it is currently detected on the system and should be possible to start (if not already started). False if it cannot be detected now but it has been detected previously.
   * @example true
   */
  active: boolean;
  /** Information about the audio stream in the source */
  audio_stream: ResourcesSourceAudioStreamResponse;
  /** The number of audio frames that has been dropped from the source. A frame is dropped in case the source is delivering frames at a faster rate than the Ingest expects it to do. */
  dropped_audio_frames: number;
  /** The number of video frames that has been dropped from the source. A frame is dropped in case the source is delivering frames at a faster rate than the Ingest expects it to do. */
  dropped_video_frames: number;
  /** The number of audio frames that has been duplicated by the ingest. If exactly one frame is missing, the ingest duplicates the coming frame to fill the gap. */
  duplicated_audio_frames: number;
  /** The number of video frames that has been duplicated by the ingest. If exactly one frame is missing, the ingest duplicates the coming frame to fill the gap. */
  duplicated_video_frames: number;
  /**
   * Flag to tell if the source is being streamed anywhere right now. False if this source is not currently used
   * @example true
   */
  in_use: boolean;
  /** The number of audio frames that has been lost from the source. If more than one frame is missing from the source they are all added to this counter. If one frame is missing, it will not be added to this counter, but to the duplicated_frames counter. */
  lost_audio_frames: number;
  /** The number of video frames that has been lost from the source. If more than one frame is missing from the source they are all added to this counter. If one frame is missing, it will not be added to this counter, but to the duplicated_frames counter. */
  lost_video_frames: number;
  /**
   * The name of the source. Will include the port number for DeckLink sources or the NDI source name for NDI sources.
   * @example "My source name"
   */
  name: string;
  /**
   * The SourceID of the source. Unique within the Ingest
   * @example 1
   */
  source_id: number;
  /** Statistics from SRT. Only included for SRT sources. */
  srt?: ResourcesSrt;
  /** Adjustment of incoming audio timestamps during the latest 250 frames. This field is meant for debugging purposes only and might be removed in future versions. */
  time_adjustment_audio: ResourcesMinMaxAverageTimings;
  /** Adjustment of incoming video timestamps during the latest 250 frames. This field is meant for debugging purposes only and might be removed in future versions. */
  time_adjustment_video: ResourcesMinMaxAverageTimings;
  /**
   * The type of interface used by the source. NDI for NDI sources, BMD for SDI or HDMI sources using a DeckLink card, SRT for SRT sources
   * @example "NDI"
   */
  type: string;
  /** Information about the video stream in the source */
  video_stream: ResourcesSourceVideoStreamResponse;
}

export interface ResourcesSourceVideoStreamResponse {
  /**
   * Frame rate denominator of this source
   * @example 1
   */
  frame_rate_d: number;
  /**
   * Frame rate numerator of this source
   * @example 50
   */
  frame_rate_n: number;
  /**
   * Height in pixels of this source
   * @example 1080
   */
  height: number;
  /**
   * Video source field mode, true if interlaced, false if progressive mode
   * @example false
   */
  interlaced: boolean;
  /**
   * SubID of this video stream
   * @example 1
   */
  sub_id: number;
  /**
   * Width in pixels of this source
   * @example 1920
   */
  width: number;
}

export interface ResourcesSrt {
  /**
   * The compression format used for the audio stream.
   * @example "AAC"
   */
  audio_format: 'AAC';
  /**
   * The number of continuity counter errors found in the input MPEG-TS of this SRT media source
   * @example 34
   */
  cc_errors: number;
  /** SRT statistics */
  connection?: ResourcesConnection;
  /** The number of successfully decoded audio frames */
  decoded_audio_frames: number;
  /** The number of successfully decoded video frames */
  decoded_video_frames: number;
  /**
   * The number of demuxed audio frames
   * @example 4582
   */
  demuxed_audio_frames: number;
  /**
   * The number of demuxed video frames
   * @example 4581
   */
  demuxed_video_frames: number;
  /** The number of audio frames that failed to decode */
  failed_decoded_audio_frames: number;
  /** The number of video frames that failed to decode */
  failed_decoded_video_frames: number;
  /**
   * The latency configured for this end of the SRT connection. The actual SRT latency negotiated between the peers is presented inside the connection object
   * @example 120
   */
  latency_ms: number;
  /**
   * The locally bound IP address.
   * @example "0.0.0.0"
   */
  local_ip?: string;
  /**
   * The locally bound port.
   * @example 1234
   */
  local_port?: number;
  /**
   * The IPv4 or IPv6 address of the remote to receive the stream from.
   * @example "0.0.0.0"
   */
  remote_ip?: string;
  /**
   * The port on the remote to receive the stream from.
   * @example 1234
   */
  remote_port?: number;
  /**
   * The mode of the SRT connection."
   * @default "listener"
   * @example "listener"
   */
  srt_mode?: 'caller' | 'listener';
  /**
   * The compression format used for the video stream.
   * @example "HEVC"
   */
  video_format: 'AVC' | 'HEVC';
}

export interface ResourcesStreamInterfaceIngest {
  /**
   * Current bandwidth usage in bits per second
   * @example 12000000
   */
  bandwidth_bps: number;
  /**
   * The commit rate in percent, i.e. how many percent of the network load is put on this interface.
   * Note that the sum of all interfaces' commit rates might exceed 100%, in case of redundancy.
   * @min 0
   * @max 100
   * @example 80
   */
  commit_rate: number;
  /**
   * IPv4 or IPv6 address on the receiving machine to which this interface sends the stream
   * @example "10.10.1.110"
   */
  ip: string;
  /**
   * The network port on the receiving machine to which this interface sends the stream
   * @example 4567
   */
  port: number;
  /**
   * The transport protocol used in this interface
   * @example "SRT"
   */
  protocol: 'SRT' | 'RIST';
  /** The number of packets sent that were retransmissions on this interface */
  retransmitted_packets: number;
  /** Round trip time in milliseconds */
  round_trip_time_ms: ResourcesRoundTripTimeMs;
  /** The number of bytes that have been sent on this interface. This metric will only work for protocol SRT. For RIST the reported value will be 0. */
  sent_bytes: number;
  /** The number of packets that have been sent on this interface. This also includes retransmitted packets. */
  sent_packets: number;
}

export interface ResourcesStreamInterfacePayload {
  /**
   * The commit rate in percent, i.e. how many percent of the network load is put on this interface.
   * Note that the sum of all interfaces' commit rates might exceed 100%, in case of redundancy.
   * @min 0
   * @max 100
   * @default 100
   */
  commit_rate?: number;
  /**
   * The local IP address to bind to. Currently only used for Protocol SRT.
   * @default "0.0.0.0"
   * @example "0.0.0.0"
   */
  local_ip?: string;
  /**
   * The network port on the receiving side to which this interface sends the data
   * @min 1024
   * @max 65535
   * @example 4567
   */
  port: number;
  /**
   * The transport protocol to use for this interface
   * @example "SRT"
   */
  protocol: 'SRT' | 'RIST';
}

export interface ResourcesStreamInterfacePipeline {
  /**
   * Current bandwidth usage in bits per second
   * @min 0
   * @example 1234
   */
  bandwidth_bps: number;
  /** The number of packets that has been recorded as dropped (unrecovered, permanently missing) by the receiving side of this interface. */
  dropped_packets: number;
  /**
   * The number of unique original packets that has been recorded as lost by the receiving side of this interface.
   * These lost packets may be recovered by retransmissions and then not be counted as "dropped" packets.
   */
  lost_packets: number;
  /**
   * The network port on the receiving machine to which this interface sends the stream
   * @example 4567
   */
  port: number;
  /**
   * The transport protocol used in this interface
   * @example "SRT"
   */
  protocol: 'SRT' | 'RIST';
  /** The number of bytes that has been received on this interface. This metric will only work for protocol SRT. For RIST the reported value will be 0. */
  received_bytes: number;
  /** The number of packets that has been received on this interface */
  received_packets: number;
  /** Round trip time in milliseconds */
  round_trip_time_ms: ResourcesRoundTripTimeMs;
}

export interface ResourcesThumbnailPayload {
  /**
   * Encoder to use for the JPEG encoding
   * @default "auto"
   * @example "auto"
   */
  encoder?: 'auto' | 'intel_gpu' | 'nvidia_gpu';
  /**
   * The height of the requested JPEG
   * @min 2
   * @max 2000
   * @example 1080
   */
  height: number;
  /**
   * Quality of the JPEG compression, from 1 (low quality) to 100 (high quality)
   * @min 1
   * @max 100
   * @example 85
   */
  quality: number;
  /**
   * The width of the requested JPEG
   * @min 2
   * @max 2000
   * @example 1920
   */
  width: number;
}

export interface ResourcesThumbnailResponse {
  /**
   * Base64 encoded JPEG data
   * @example "<Base64 encoded JPEG data>"
   */
  data: string;
  /**
   * The 32 most significant bits in the 64 bit TAI timestamp of the video frame the thumbnail was generated from, counted in microseconds since UNIX epoch
   * @example 383292
   */
  timestamp_high32: number;
  /**
   * The 32 least significant bits in the 64 bit TAI timestamp of the video frame the thumbnail was generated from, counted in microseconds since UNIX epoch
   * @example 2901321568
   */
  timestamp_low32: number;
}

export interface ResourcesUUIDResponse {
  /**
   * UUID of the resource
   * @format uuid
   * @example "00000000-0000-0000-0000-000000000000"
   */
  uuid: string;
}

export interface ResourcesView {
  /**
   * Height in pixels of this view
   * @min 20
   * @max 8192
   * @example 540
   */
  height: number;
  /**
   * The input slot to use for this view
   * @min 0
   * @example 1
   */
  input_slot: number;
  /**
   * Label to put under this view. Leave empty or omit to disable
   * @maxLength 256
   * @example "Camera 1"
   */
  label: string;
  /**
   * Width in pixels of this view
   * @min 20
   * @max 8192
   * @example 960
   */
  width: number;
  /**
   * The X position in the composited output of this view's top left corner, in pixels from the left side of the image
   * @min 0
   * @max 8192
   * @example 0
   */
  x: number;
  /**
   * The Y position in the composited output of this view's top left corner, in pixels from the top of the image
   * @min 0
   * @max 8192
   * @example 0
   */
  y: number;
}

export interface TypesEncoderData {
  devices: TypesRenderDevice[];
  /**
   * The name and type of the encoder
   * @example "nvidia_gpu"
   */
  name: 'intel_gpu' | 'nvidia_gpu';
}

export interface TypesRenderDevice {
  /**
   * Identifier of the encoder device
   * @example 0
   */
  id: number;
  /**
   * Human readable name of the encoder device
   * @example "Nvidia RTX 4000"
   */
  name: string;
}
